{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Goliass/projetoImersaoAluraIAGemini-petFinder/blob/main/projetoImersaoAluraIAGemini_petFinder_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XS9uooelPukL"
      },
      "outputs": [],
      "source": [
        "# PROGRAM 1 START\n",
        "\"\"\"\n",
        "At the command line, only need to run once to install the package via pip:\n",
        "\n",
        "$ pip install google-generativeai\n",
        "\"\"\"\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "root_path=\"/content/drive/MyDrive/Colab Notebooks/pet_finder\" # /content/drive/MyDrive/... (Google drive folder)   OR    /content (temporary/runtime Colab folder)\n",
        "\n",
        "training_model_images_dir = [\"training_model_images/1_image_identification\", \"training_model_images/2_image_description\"] # images for training / for the model to use as a benchmark to evaluate other images\n",
        "input_images_dir = \"input_images\" # images to process\n",
        "processed_images_dir = \"processed_images\"\n",
        "\n",
        "processed_images_path = f\"{root_path}/processed_images.json\"\n",
        "\n",
        "# create the directories\n",
        "for images_dir in training_model_images_dir:\n",
        "    fullpath = f\"{root_path}/{images_dir}\"\n",
        "\n",
        "    if not os.path.exists(fullpath):\n",
        "        os.makedirs(fullpath)\n",
        "        print(f\"Directory '{fullpath}' created successfully!\")\n",
        "\n",
        "fullpath = f\"{root_path}/{input_images_dir}\"\n",
        "if not os.path.exists(fullpath):\n",
        "    os.mkdir(fullpath)\n",
        "    print(f\"Directory '{fullpath}' created successfully!\")\n",
        "\n",
        "fullpath = f\"{root_path}/{processed_images_dir}\"\n",
        "if not os.path.exists(fullpath):\n",
        "    os.mkdir(fullpath)\n",
        "    print(f\"Directory '{fullpath}' created successfully!\")\n",
        "\n",
        "genai.configure(api_key=userdata.get('imersaoIAAluraGemini'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJw5c-XYQJHA"
      },
      "outputs": [],
      "source": [
        "def identify_image(image):\n",
        "  # Set up the model [start]\n",
        "  generation_config = {\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 32,\n",
        "    \"max_output_tokens\": 1024,\n",
        "  }\n",
        "\n",
        "  safety_settings = [\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "  ]\n",
        "\n",
        "  model = genai.GenerativeModel(model_name=\"gemini-1.0-pro-vision-latest\",\n",
        "                                generation_config=generation_config,\n",
        "                                safety_settings=safety_settings)\n",
        "\n",
        "  # Set up the model [end]\n",
        "\n",
        "  prompt_parts = [\n",
        "    \"Descreva a imagem como 'animal', 'texto' ou 'nenhum'. 1. Se a maior parte da imagem for um animal, descreva-a apenas com a palavra 'animal'; 2.Se a maior parte da imagem for texto, descreva-a apenas com a palavra 'texto'; 3. Se a maior parte da imagem não for nem texto nem um animal, descreva-a apenas com a palavra 'nenhum'.\",\n",
        "    \"Object: \",\n",
        "    genai.upload_file(f\"{root_path}/{training_model_images_dir[0]}/identifyImage (1).jpg\"),\n",
        "    \"Description:'animal'\",\n",
        "    \"Object: \",\n",
        "    genai.upload_file(f\"{root_path}/{training_model_images_dir[0]}/identifyImage (2).jpg\"),\n",
        "    \"Description:'texto'\",\n",
        "    \"Object: \",\n",
        "    genai.upload_file(f\"{root_path}/{training_model_images_dir[0]}/identifyImage (3).jpg\"),\n",
        "    \"Description:'nenhum'\",\n",
        "    \"Object: \",\n",
        "    genai.upload_file(f\"{root_path}/{training_model_images_dir[0]}/identifyImage (4).jpg\"),\n",
        "    \"Description:'nenhum'\",\n",
        "    \"Object: \",\n",
        "    genai.upload_file(f\"{root_path}/{training_model_images_dir[0]}/identifyImage (5).jpg\"),\n",
        "    \"Description:'nenhum'\",\n",
        "    \"Object: \",\n",
        "    genai.upload_file(f\"{root_path}/{training_model_images_dir[0]}/identifyImage (6).jpg\"),\n",
        "    \"Description:'nenhum'\",\n",
        "    \"Object: \",\n",
        "    genai.upload_file(f\"{root_path}/{training_model_images_dir[0]}/identifyImage (7).jpg\"),\n",
        "    \"Description:'nenhum'\",\n",
        "\n",
        "    \"Object: \",\n",
        "    genai.upload_file(image),\n",
        "    \"Description:\",\n",
        "  ]\n",
        "\n",
        "  response = model.generate_content(prompt_parts)\n",
        "\n",
        "  return response.text\n",
        "\n",
        "# print(identify_image(f'{root_path}/input_images/C6-E2jZLH4- (1).jpg')) # for testing purposes\n",
        "# print(identify_image(f'{root_path}/input_images/C6-E2jZLH4- (2).jpg')) # tfor testing purposes\n",
        "# print(identify_image(f'{root_path}/training_model_images/1_image_identification/identifyImage (3).jpg')) # for testing purposes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-Q1DMKeVWPR"
      },
      "outputs": [],
      "source": [
        "def obtain_image_text(image):\n",
        "  generation_config = {\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 32,\n",
        "    \"max_output_tokens\": 4096,\n",
        "  }\n",
        "\n",
        "\n",
        "  safety_settings = [\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "  ]\n",
        "\n",
        "\n",
        "  model = genai.GenerativeModel(model_name=\"gemini-1.0-pro-vision-latest\",\n",
        "                                generation_config=generation_config,\n",
        "                                safety_settings=safety_settings)\n",
        "  # Set up the model [end]\n",
        "\n",
        "  prompt_parts = [\n",
        "    \"Obtenha todo o texto da imagem.\",\n",
        "    \"Object: \",\n",
        "    genai.upload_file(f\"{root_path}/{training_model_images_dir[1]}/describe_image (2).jpg\"),\n",
        "    \"Description: Resgatado: Cachorro. Onde foi encontrado/entregue: Resgatada em Eldorado do Sul, entregue no Pontal. Características (porte, cor, etc.): Fêmea. Porte P/M, cor caramelo, pelo curto, estava com as tetinhas inchadas. Com quem está: Está em uma LT na zona sul de Porto Alegre com Ana. @anaflaviabastos. Entrar em contato com: Ana Flávia Bastos. IG: anaflaviabastos\",\n",
        "    \"Object: \",\n",
        "    genai.upload_file(f\"{root_path}/{training_model_images_dir[1]}/describe_image (4).jpg\"),\n",
        "    \"Description: Procura-se: Gato. Perdido em (cidade, bairro e rua): Scharlau São Leopoldo - Rua pérola. Características (porte, cor, etc.): Macho. Gato siamês bem gordinho, se chama Sheik. Entre em contato com (Instagram, telefone): Ronaldo 51 99231-4173. Instagram @karolkapazi. *mande junto com o formulário uma foto do animal.\",\n",
        "    \"Object: \",\n",
        "    genai.upload_file(f\"{root_path}/{training_model_images_dir[1]}/describe_image (5).jpg\"),\n",
        "    \"Description: Resgatado: Onde foi encontrado/entregue: Resgatada na enchente. Mathias velho. Características (porte, cor, etc.): Fêmea. Fêmea, branca, pelagem média, olhos amarelados, rabo peludo tá com pontos da cirurgia de castração... Com quem/onde está: Bairro Igará - Canoas. Entrar em contato com: @leonardo.serrao. *mande junto\",\n",
        "    \"Object: \",\n",
        "    genai.upload_file(f\"{root_path}/{training_model_images_dir[1]}/describe_image (6).jpg\"),\n",
        "    \"Description: Resgatado: Cachorro. Onde foi encontrado/entregue: Cairu/Parque Germânia. Características (porte, cor, etc.): Macho. Porte P, castrado, preto com peito e patas brancas. Com quem/onde está: Milena/Porto Alegre. Entrar em contato com: @paixao4patas.\",\n",
        "\n",
        "    \"Object: \",\n",
        "    genai.upload_file(image),\n",
        "    \"Description: \",\n",
        "  ]\n",
        "\n",
        "  response = model.generate_content(prompt_parts)\n",
        "  return response.text\n",
        "\n",
        "# print(obtain_image_text(f'{root_path}/input_images/C6-E2jZLH4- (1).jpg')) # for testing purposes\n",
        "# print(obtain_image_text(f'{root_path}/input_images/C6-QyPoLuvN (1).jpg')) # for testing purposes\n",
        "# print(obtain_image_text(f'{root_path}/input_images/C6_2nBdrhYO (1).jpg')) # for testing purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9o69y4Q4Ec2"
      },
      "outputs": [],
      "source": [
        "def describe_animal_image(image):\n",
        "  # Set up the model [start]\n",
        "  generation_config = {\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 32,\n",
        "    \"max_output_tokens\": 4096,\n",
        "  }\n",
        "\n",
        "\n",
        "  safety_settings = [\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "  ]\n",
        "\n",
        "\n",
        "  model = genai.GenerativeModel(model_name=\"gemini-1.0-pro-vision-latest\",\n",
        "                                generation_config=generation_config,\n",
        "                                safety_settings=safety_settings)\n",
        "  # Set up the model [end]\n",
        "\n",
        "  prompt_parts = [\n",
        "  \"Descreva as características físicas do animal, e somente as partes que aparecem. Não descrever as demais informações da imagem.\",\n",
        "  \"Object: \",\n",
        "  genai.upload_file(f\"{root_path}/{training_model_images_dir[1]}/describe_image (1).jpg\"),\n",
        "  \"Description: Cachorro caramelo, de porte médio, com pelos curtos e marrons, com uma mancha branca no peito. Tem olhos castanhos escuros. Ele está usando uma coleira azul e branca. As duas orelhas estão abaixadas, ambas são da cor marrom. As bochechas são brancas.\",\n",
        "  \"Object: \",\n",
        "  genai.upload_file(f\"{root_path}/{training_model_images_dir[1]}/describe_image (3).jpg\"),\n",
        "  \"Description: Gato de porte pequeno, com pelagem marrom curta e lisa e listras pretas. As orelhas são pontudas, na cor marrom e com pelos brancos em seu interior. Os olhos são verdes. Os bigodes são brancos. Ele tem uma mancha branca no peito e no rosto.\",\n",
        "  \"Object: \",\n",
        "  genai.upload_file(f\"{root_path}/{training_model_images_dir[1]}/describe_image (8).jpg\"),\n",
        "  \"Description: Cachorro de porte grande, com pelos curtos e pretos. Ele tem uma mancha amarela no focinho, acima dos olhos e nas patas dianteiras. As orelhas são caídas e pretas.\",\n",
        "  \"Object: \",\n",
        "  genai.upload_file(f\"{root_path}/{training_model_images_dir[1]}/describe_image (7).jpg\"),\n",
        "  \"Description: Gato de porte médio/grande, com pelos longos e pretos. Os olhos são amarelos. As orelhas são pontudas e pretas. A cauda é longa e preta.\",\n",
        "\n",
        "  \"Object: \",\n",
        "  genai.upload_file(image),\n",
        "  \"Description: \",\n",
        "  ]\n",
        "\n",
        "  response = model.generate_content(prompt_parts)\n",
        "  return response.text\n",
        "\n",
        "# print(describe_animal_image(f'{root_path}/input_images/C6-EjnFrBIx (1).jpg')) # for testing purposes\n",
        "# print(describe_animal_image(f'{root_path}/input_images/C6-QyPoLuvN (2).jpg')) # for testing purposes\n",
        "# print(describe_animal_image(f'{root_path}/input_images/C6-RyXFLyHG (1).jpg')) # for testing purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7-eXFuJFBlno"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def image_descr_already_processed(filename): # image description already generated\n",
        "    processed = False\n",
        "\n",
        "    if os.path.exists(processed_images_path):\n",
        "        # open file for reading\n",
        "        with open(processed_images_path, \"r\") as archive:\n",
        "            # array objects loading from json file\n",
        "            images_descr_from_file = json.load(archive)\n",
        "\n",
        "\n",
        "        images_descr_from_file_str = \"\".join(str(images_descr_from_file))\n",
        "        processed = filename.lower() in images_descr_from_file_str.lower()\n",
        "\n",
        "    return processed\n",
        "\n",
        "def save_images_descr_to_json_file(images_descr):\n",
        "    images_descr_from_file = []\n",
        "\n",
        "    if images_descr:\n",
        "        if os.path.exists(processed_images_path):\n",
        "            # open file for reading\n",
        "            with open(processed_images_path, \"r\") as archive:\n",
        "                # array objects loading from json file\n",
        "                images_descr_from_file = json.load(archive)\n",
        "\n",
        "        images_descr_from_file.extend(images_descr)\n",
        "\n",
        "        with open(processed_images_path, \"w\") as archive:\n",
        "            # recording of the array of objects to the file as JSON\n",
        "            json.dump(images_descr_from_file, archive)\n",
        "\n",
        "def move_processed_images(new_images_descr):\n",
        "    for image in new_images_descr:\n",
        "        input_images_path = f\"{root_path}/{input_images_dir}/{image['filename']}\"\n",
        "        processed_images_path = f\"{root_path}/{processed_images_dir}/{image['filename']}\"\n",
        "\n",
        "        try:\n",
        "            os.rename(input_images_path, processed_images_path)\n",
        "        except:\n",
        "            pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VNJBfLHuSx_",
        "outputId": "7b012249-0eb4-4ce9-c1ee-933384fc16f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processed images: []\n"
          ]
        }
      ],
      "source": [
        "def generate_images_description(amount):\n",
        "    folder_path = f\"{root_path}/{input_images_dir}/\"\n",
        "\n",
        "    input_files = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "\n",
        "        if filename.endswith(\".jpg\") and not image_descr_already_processed(filename):\n",
        "            input_files.append(filename)\n",
        "\n",
        "    images_desc = []\n",
        "    index = 0;\n",
        "\n",
        "    for filename in input_files:\n",
        "        image_path = f\"{root_path}/{input_images_dir}/{filename}\"\n",
        "        image_is = identify_image(image_path).strip()\n",
        "\n",
        "        if image_is == \"'animal'\":\n",
        "            image_description = describe_animal_image(image_path)\n",
        "        elif image_is == \"'texto'\":\n",
        "            image_description = obtain_image_text(image_path)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        first_sentence = image_description.split('.')[0].strip()\n",
        "\n",
        "        images_desc.append({\n",
        "            \"filename\": filename,\n",
        "            \"title\": first_sentence,\n",
        "            \"AI_description\": image_description.strip()\n",
        "        })\n",
        "\n",
        "        if amount:\n",
        "            index += 1\n",
        "\n",
        "            if index >= amount:\n",
        "                break\n",
        "\n",
        "    return images_desc\n",
        "\n",
        "def process_images(amount):\n",
        "    new_images_descr = []\n",
        "\n",
        "    new_images_descr = generate_images_description(amount)\n",
        "    print(\"processed images:\", new_images_descr)\n",
        "\n",
        "    save_images_descr_to_json_file(new_images_descr)\n",
        "    move_processed_images(new_images_descr)\n",
        "\n",
        "\n",
        "process_images()\n",
        "\n",
        "# PROGRAM 1 END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46O-WP7NAFGH"
      },
      "outputs": [],
      "source": [
        "# PROGRAM 2 START\n",
        "\"\"\"\n",
        "At the command line, only need to run once to install the package via pip:\n",
        "\n",
        "$ pip install google-generativeai\n",
        "\"\"\"\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "root_path=\"/content/drive/MyDrive/Colab Notebooks/pet_finder\" # /content/drive/MyDrive/... (Google drive folder)   OR    /content (temporary/runtime Colab folder)\n",
        "\n",
        "training_model_images_dir = [\"training_model_images/1_image_identification\", \"training_model_images/2_image_description\"] # images for training / for the model to use as a benchmark to evaluate other images\n",
        "input_images_dir = \"input_images\" # images to process\n",
        "processed_images_dir = \"processed_images\"\n",
        "\n",
        "processed_images_path = f\"{root_path}/processed_images.json\"\n",
        "\n",
        "# create the directories\n",
        "for images_dir in training_model_images_dir:\n",
        "    fullpath = f\"{root_path}/{images_dir}\"\n",
        "\n",
        "    if not os.path.exists(fullpath):\n",
        "        os.makedirs(fullpath)\n",
        "        print(f\"Directory '{fullpath}' created successfully!\")\n",
        "\n",
        "fullpath = f\"{root_path}/{input_images_dir}\"\n",
        "if not os.path.exists(fullpath):\n",
        "    os.mkdir(fullpath)\n",
        "    print(f\"Directory '{fullpath}' created successfully!\")\n",
        "\n",
        "fullpath = f\"{root_path}/{processed_images_dir}\"\n",
        "if not os.path.exists(fullpath):\n",
        "    os.mkdir(fullpath)\n",
        "    print(f\"Directory '{fullpath}' created successfully!\")\n",
        "\n",
        "genai.configure(api_key=userdata.get('imersaoIAAluraGemini'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t91BIiorasM-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def embed_image(title, text):\n",
        "  return genai.embed_content(model=\"models/embedding-001\",\n",
        "                                 content=text,\n",
        "                                 title=title,\n",
        "                                 task_type=\"RETRIEVAL_DOCUMENT\")[\"embedding\"] # \"embedding\" is the field of the result, chosen as the return of the function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4YNITNia1b4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_and_search_query(query, df, model, top_x_values):\n",
        "  # generation of the embedding of the query\n",
        "  query_embedding = genai.embed_content(model=\"models/embedding-001\",\n",
        "                                 content=query,\n",
        "                                 task_type=\"RETRIEVAL_QUERY\")[\"embedding\"]\n",
        "\n",
        "  # Calculates the distance/proximity of each document (image description) with the desired search/query\n",
        "  dot_products = np.dot(np.stack(df[\"Embeddings\"]), query_embedding)\n",
        "\n",
        "  # search in the scalar products, determining which document stands out the most (highest contextual proximity to the desired search/query), returning its ID\n",
        "  index = np.argmax(dot_products)\n",
        "\n",
        "  import heapq\n",
        "  np_array = np.array(dot_products)\n",
        "  # get the index of the x maximum values (highest proximity) of an array (without sorting it)\n",
        "  top_x_indexes = heapq.nlargest(top_x_values, range(len(np_array)), np_array.take)\n",
        "\n",
        "  print(top_x_indexes)\n",
        "\n",
        "  top_x_results = []\n",
        "  for index in top_x_indexes:\n",
        "    row = df.iloc[index];\n",
        "    top_x_results.append({\"filename\": row[\"Filename\"], \"title\": row[\"Title\"], \"description\": row[\"Description\"]})\n",
        "\n",
        "  return top_x_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_aJlB27a3O6"
      },
      "outputs": [],
      "source": [
        "def display_search_results(query, search_results):\n",
        "  from IPython.display import Image, display\n",
        "\n",
        "  processed_images_path = f\"{root_path}/{processed_images_dir}/\"\n",
        "\n",
        "  print(f\"\\nExibindo resultados para a busca '{query}':\\n\")\n",
        "  for result in search_results:\n",
        "      print(result['filename'])\n",
        "      print(result['title'])\n",
        "      print(result['description'])\n",
        "      display(Image(processed_images_path+result['filename']))\n",
        "      print(\"-------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "      print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjzSJvrq2g4q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def entrada_dados():\n",
        "    model = \"models/embedding-001\"\n",
        "    images_descr = []\n",
        "\n",
        "    if os.path.exists(processed_images_path):\n",
        "        # open file for reading\n",
        "        with open(processed_images_path, \"r\") as archive:\n",
        "            # array objects loading from json file\n",
        "            images_descr = json.load(archive)\n",
        "\n",
        "        if images_descr:\n",
        "            df = pd.DataFrame(images_descr)\n",
        "            df.columns = [\"Filename\", \"Title\", \"Description\"]\n",
        "\n",
        "            print(\"Aguarde, carregando dados dos pets...\\n\\n\")\n",
        "\n",
        "            # adds the result of the embed_image function in the new Embeddings field in the dataframe (df)\n",
        "            df[\"Embeddings\"] = df.apply(lambda row: embed_image(row[\"Title\"], row[\"Description\"]), axis=1)\n",
        "\n",
        "\n",
        "            input_text='\\nPressione Enter para sair ou \\nFaça sua pergunta relacionada ao pet \\n(Tem animal da cidade x?, tem gatos pretos?, tem cachorros de tamanho grande? etc):\\n\\n'\n",
        "            query = input(input_text)\n",
        "\n",
        "            while query:\n",
        "                print(\"Buscando...\")\n",
        "                search_results = generate_and_search_query(query, df, model, 6)\n",
        "\n",
        "                display_search_results(query, search_results)\n",
        "                query = input(input_text)\n",
        "\n",
        "entrada_dados()\n",
        "# PROGRAM 2 END"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOAZyv+9pGsIPB5mP4VeYng",
      "include_colab_link": true,
      "mount_file_id": "1uB7q1DpzzAcsb0ff3NrM64ib3sPXi4E2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
